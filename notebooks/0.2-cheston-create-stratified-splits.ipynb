{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stratified data splitting:",
   "id": "13f57cb68e6a4671"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Problem statement\n",
    "\n",
    "Each recording has metadata:\n",
    "- pianist (20 classes)\n",
    "- setting ∈ {solo, trio}\n",
    "- album_id (group)\n",
    "- composition_id (group)\n",
    "\n",
    "And we need:\n",
    "- 8/1/1 ratio\n",
    "- Solo/trio proportion preserved\n",
    "- Each pianist in every split\n",
    "- No album leakage\n",
    "- No composition leakage"
   ],
   "id": "468aeb1beb460c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:39:21.131410Z",
     "start_time": "2026-02-06T13:39:21.128924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pulp\n",
    "import unidecode\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from deep_pianist_identification import utils"
   ],
   "id": "1c130aa199588c14",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:00:59.003147Z",
     "start_time": "2026-02-06T13:00:58.995034Z"
    }
   },
   "cell_type": "code",
   "source": "SIMILARITY_THRESH = 0.9\n",
   "id": "9f61550658ebaa89",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Metadata curation\n",
    "\n",
    "Given that the track names in JTD and PiJAMA are not resolved to their unique compositions (e.g., \"A Night in Tunisia\", \"Night in Tunisia\", \"An Night in Tunisia (Alternative Take)\" can all appear!), we use a human-in-the-loop pipeline to resolve these:\n",
    "- Grab \"raw\" track names from JTD and PiJAMA, convert these to lowercase, and remove punctuation\n",
    "- Clean up \"junk\" words and phrases with hardcoded regular expressions (e.g., 'Alternate Take', 'Interrupted', 'Live at the Maybeck Recital Hall')\n",
    "    - Already, these two stages reduce the number of unique compositions from over 3000 to 2450\n",
    "- Next, we map \"contrafact\" pieces onto their original composition, using a list of 450 composition pairs curated manually by a professional jazz musician\n",
    "    - E.g., the Sonny Rollins tune \"Oleo\" is mapped onto the Gershwin composition \"I Got Rhythm\", which uses the same chords\n",
    "    - We chose to do this as the performances in JTD are \"solos only\", meaning the melody (the only thing different between \"Oleo\" and \"I Got Rhythm\") is not likely not present\n",
    "- Using a SentenceBERT model pretrained on 1B sentences, we extract embeddings for every cleaned title\n",
    "    - We then compute the cosine similarity pairwise between every sentence, and use these scores to construct a graph: when the cosine similarity of two titles exceeds a threshold, we connect these two titles along an edge.\n",
    "    - We tune the threshold manually and set it to 0.9 following preliminary experiments\n",
    " - After this process, we are left with 2348 unique compositions\n",
    "    - We then manually correct any remaining misidentified compositions.\n",
    "        - These are usually the results of spelling mistakes in the original track listings that were not resolved by the SentenceBERT clustering, e.g. Miserioso -> Misterioso (Monk tune), Sloliloquy -> Soliloquy.\n",
    "    - This leads to a final canonic list of 2216 unique compositions\n",
    "\n",
    "This process is significantly more advanced that the process followed previously by Edwards et al. (2023) to map compositions in PiJAMA to jazz standards, which used only a small number of hardcoded regular expressions. We release our finegrained annotations of both the complete JTD and PiJAMA datasets to the community as part of this paper, and anticipate that they may find use in cover song and jazz standard identification work."
   ],
   "id": "5c3c580790018d5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:01:07.221005Z",
     "start_time": "2026-02-06T13:01:07.037435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load up all metadata JSON files\n",
    "js_files = list((Path(utils.get_project_root()) / \"data\").rglob(\"**/*.json\"))\n"
   ],
   "id": "c4e9ad840fb14ade",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:46:26.381397Z",
     "start_time": "2026-02-05T15:46:25.856428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read all JSONs, create metadata df\n",
    "all_metadata = []\n",
    "columns_to_keep = [\"track_name\", \"album_name\", \"bandleader\", \"pianist\", \"recording_year\", \"mbz_id\"]\n",
    "for js_file in js_files:\n",
    "    with open(js_file) as f:\n",
    "        metadata = json.load(f)\n",
    "    res = {k: v for k, v in metadata.items() if k in columns_to_keep}\n",
    "    all_metadata.append(res)\n",
    "df = pd.DataFrame(all_metadata)"
   ],
   "id": "6d1db0d367ed0f3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Remove \"junk\"\n",
    "\n",
    "Start by removing junk words/phrases and fillers that never belong to the core title of a track"
   ],
   "id": "44ecce2cdb014965"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:46:27.610182Z",
     "start_time": "2026-02-05T15:46:27.603473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "META_WORDS = {\n",
    "    \"take\", \"alt\", \"alternate\", \"version\", \"edit\",\n",
    "    \"live\", \"remastered\", \"remaster\", \"mono\", \"stereo\",\n",
    "    \"demo\", \"session\", \"rehearsal\", \"outtake\",\n",
    "    \"bonus\", \"track\", \"disc\", \"cd\",\n",
    "    \"instrumental\", \"vocal\",\n",
    "    \"complete\", \"interrupted\",\n",
    "    \"excerpt\", \"outro\",\n",
    "    \"reprise\", \"medley\", \"intro\", \"recorded\",\n",
    "    \"sequence\", \"first\", \"second\"\n",
    "}\n",
    "ARTICLES = {\"a\", \"an\", \"the\"}\n",
    "\n",
    "\n",
    "def remove_junk(title: str) -> str:\n",
    "    \"\"\"\n",
    "    We need to remove 'junk' information from titles, like take information, 'remastered', etc.\n",
    "    \"\"\"\n",
    "    # 1. Basic cleanup\n",
    "    t = title.lower()\n",
    "    t = unidecode.unidecode(t)\n",
    "    # Normalize quotes/apostrophes\n",
    "    t = t.replace(\"’\", \"'\").replace(\"`\", \"'\")\n",
    "    # Replace \"&\" with \"and\"\n",
    "    t = t.replace(\"&\", \"and\").replace(\"+\", \"and\")\n",
    "\n",
    "    # 2. Remove parentheticals and brackets\n",
    "    # (live at ...) [alt take] {demo}\n",
    "    t = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \" \", t)\n",
    "\n",
    "    # If all numeric, return original\n",
    "    if all(t_.isdigit() for t_ in t.split()):\n",
    "        return t\n",
    "\n",
    "    # 3. Remove common recording annotations\n",
    "    patterns = [\n",
    "        # Take numbers\n",
    "        r\"\\btake\\s*\\d+\\b\",\n",
    "        r\"\\btk\\s*\\d+\\b\",\n",
    "        # Alternate versions\n",
    "        r\"\\balt(ernate)?\\b\",\n",
    "        r\"\\bversion\\b\",\n",
    "        r\"\\bedited?\\b\",\n",
    "        # Live / venue\n",
    "        r\"\\blive\\b.*$\",\n",
    "        # r\"\\bat\\s+[a-z0-9\\s]+\\b\",\n",
    "        # Dates\n",
    "        r\"\\b\\d{4}\\b\",\n",
    "        r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\",\n",
    "        # Disc / track numbers\n",
    "        r\"\\b(cd|disc|track)\\s*\\d+\\b\",\n",
    "        # Remaster info\n",
    "        r\"\\b(remaster(ed)?|mono|stereo)\\b\",\n",
    "        # Session info\n",
    "        r\"\\b(session|rehearsal|outtake|demo)\\b\",\n",
    "        # Arrangement info\n",
    "        r\"\\b(instrumental|vocal)\\b\",\n",
    "        # From soundtrack / album\n",
    "        # r\"\\bfrom\\s+.*$\"\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        t = re.sub(p, \" \", t)\n",
    "\n",
    "    # 4. Remove punctuation\n",
    "    t = re.sub(r\"[^\\w\\s]\", \" \", t)\n",
    "\n",
    "    # 5. Token cleanup\n",
    "    tokens = t.split()\n",
    "    cleaned = []\n",
    "    for w in tokens:\n",
    "        # Remove pure numbers\n",
    "        if w.isdigit():\n",
    "            continue\n",
    "        # Remove articles\n",
    "        # if w in ARTICLES:\n",
    "        #     continue\n",
    "        # Remove meta words\n",
    "        if w in META_WORDS:\n",
    "            continue\n",
    "        cleaned.append(w)\n",
    "\n",
    "    # 6. Rejoin and collapse spaces\n",
    "    t = \" \".join(cleaned)\n",
    "\n",
    "    if t == \"\":\n",
    "        t = re.sub(r\"[^\\w\\s]\", \" \", title.lower())\n",
    "        return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n"
   ],
   "id": "26ef53f4b7dca055",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:46:30.028916Z",
     "start_time": "2026-02-05T15:46:29.976416Z"
    }
   },
   "cell_type": "code",
   "source": "dejunked = {t: remove_junk(t) for t in df[\"track_name\"].unique()}",
   "id": "a1bc873273f53a36",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:46:48.699336Z",
     "start_time": "2026-02-05T15:46:48.683775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now, map dejunked/contrafacted titles back to original titles\n",
    "df[\"dejunked_track_name\"] = df[\"track_name\"].map(dejunked)"
   ],
   "id": "82508eb621664a6f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:47:02.806800Z",
     "start_time": "2026-02-05T15:47:02.802090Z"
    }
   },
   "cell_type": "code",
   "source": "print(df[\"dejunked_track_name\"].nunique(), df[\"track_name\"].nunique())",
   "id": "cf4a10a14d698aec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450 3044\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Map contrafacts to original compositions\n",
    "\n",
    "We have a list of jazz contrafacts saved in `references/jazz_contrafacts.csv`: we can map compositions using this"
   ],
   "id": "1f899ab65b4af38d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:04:34.830522Z",
     "start_time": "2026-02-05T14:04:34.805251Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "contrafacts_path = Path(utils.get_project_root()) / \"references/jazz_contrafacts.csv\"\n",
    "contrafacts_df = pd.read_csv(contrafacts_path)\n",
    "\n",
    "# apply dejunking\n",
    "contrafacts_df[\"contrafact_dj\"] = contrafacts_df[\"Contrafact\"].apply(remove_junk)\n",
    "contrafacts_df[\"original_dj\"] = contrafacts_df[\"Original Song\"].apply(remove_junk)\n",
    "\n",
    "contrafacts_dj = contrafacts_df[[\"contrafact_dj\", \"original_dj\"]]\n",
    "contrafacts_mapping = {c: d for c, d in contrafacts_dj.to_numpy()}"
   ],
   "id": "62b91f07d312bc89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:04:34.854839Z",
     "start_time": "2026-02-05T14:04:34.851795Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "# remove contrafacts from dejunked list\n",
    "for k, c in dejunked.items():\n",
    "    if c in contrafacts_mapping:\n",
    "        dejunked[k] = contrafacts_mapping[c]\n"
   ],
   "id": "e588571c263c3cff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Compute similarity\n",
    "\n",
    "Use a pretrained SentenceBERT model to compute inter-composition similarity. We set a `SIMILARITY_THRESH` and use this to add edges between a graph connecting compositions together."
   ],
   "id": "4d22a99f5fe9bfbf"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-05T14:04:43.275009Z",
     "start_time": "2026-02-05T14:04:34.955408Z"
    }
   },
   "source": [
    "bert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "titles = df[\"dejunked_track_name\"].tolist()\n",
    "embeddings = bert.encode(titles, normalize_embeddings=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb3093382147447cac72e39a602f3bbe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:04:55.662149Z",
     "start_time": "2026-02-05T14:04:43.342319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sim = cosine_similarity(embeddings)\n",
    "\n",
    "G = nx.Graph()\n",
    "for i in range(len(titles)):\n",
    "    for j in range(i + 1, len(titles)):\n",
    "        if sim[i, j] > SIMILARITY_THRESH:\n",
    "            G.add_edge(i, j)\n",
    "\n",
    "clusters = list(nx.connected_components(G))"
   ],
   "id": "b1fcd6b4e6726eb7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can map compositions back onto their named entity",
   "id": "8c33e13a80393688"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:04:55.756335Z",
     "start_time": "2026-02-05T14:04:55.707199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_mapping = {}\n",
    "for clust in clusters:\n",
    "    resolved = df[\"dejunked_track_name\"].iloc[list(clust)].to_list()\n",
    "    # use the shortest title as the correct one\n",
    "    smallest = min(resolved, key=len)\n",
    "    for r in resolved:\n",
    "        cluster_mapping[r] = smallest\n",
    "\n",
    "df[\"clustered_track_name\"] = df[\"dejunked_track_name\"].map(cluster_mapping).fillna(df[\"dejunked_track_name\"])"
   ],
   "id": "382cd24f47b2cbc6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Human-in-the-loop\n",
    "\n",
    "Now, we manually look through this dataframe and resolve any final track names manually. This creates a df, which we've saved already as `references/canonical_track_names.csv`.\n",
    "\n",
    "Finally, we iterate through this DF and update the `metadata.json` for each track"
   ],
   "id": "c7e9488f2c5b9594"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T15:39:39.544091Z",
     "start_time": "2026-02-05T15:39:39.504934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We've already done this, so update the metadata with the canonic track names\n",
    "canonic_df = pd.read_csv(Path(utils.get_project_root()) / \"references/canonical_track_names.csv\")\n",
    "canonic_mapping = {k: v for (k, v) in canonic_df[[\"mbz_id\", \"final_track_name\"]].to_numpy()}"
   ],
   "id": "b75fd42f6a92c45c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T16:03:01.540763Z",
     "start_time": "2026-02-05T16:03:00.456255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, js in enumerate(js_files):\n",
    "    with open(js, \"r\") as js_in:\n",
    "        js_read = json.load(js_in)\n",
    "\n",
    "    js_read[\"composition_canonic\"] = canonic_mapping[js_read[\"mbz_id\"]]\n",
    "\n",
    "    with open(js, \"w\") as js_out:\n",
    "        json.dump(js_read, js_out, indent=4, ensure_ascii=False)"
   ],
   "id": "9a33c067825d7e7d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stratified Splitting\n",
    "\n",
    "First, load up the data to be splitted. We only want to keep the top 20 pianists, again."
   ],
   "id": "8fac15309ab22164"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:01:11.985093Z",
     "start_time": "2026-02-06T13:01:11.980231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DESIRED_PIANISTS = [\n",
    "    \"Abdullah Ibrahim\",\n",
    "    \"Ahmad Jamal\",\n",
    "    \"Bill Evans\",\n",
    "    \"Brad Mehldau\",\n",
    "    \"Cedar Walton\",\n",
    "    \"Chick Corea\",\n",
    "    \"Gene Harris\",\n",
    "    \"Geri Allen\",\n",
    "    \"Hank Jones\",\n",
    "    \"John Hicks\",\n",
    "    \"Junior Mance\",\n",
    "    \"Keith Jarrett\",\n",
    "    \"Kenny Barron\",\n",
    "    \"Kenny Drew\",\n",
    "    \"McCoy Tyner\",\n",
    "    \"Oscar Peterson\",\n",
    "    \"Stanley Cowell\",\n",
    "    \"Teddy Wilson\",\n",
    "    \"Thelonious Monk\",\n",
    "    \"Tommy Flanagan\",\n",
    "]"
   ],
   "id": "adfe7e527d40c82b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:01:13.475660Z",
     "start_time": "2026-02-06T13:01:13.141250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_in = []\n",
    "split_cols = [\"track_name\", \"album_name\", \"pianist\", \"composition_canonic\"]\n",
    "\n",
    "for js in js_files:\n",
    "    with open(js, \"r\") as js_in:\n",
    "        js_read = json.load(js_in)\n",
    "\n",
    "    if js_read[\"pianist\"] in DESIRED_PIANISTS:\n",
    "        js_res = {k: v for k, v in js_read.items() if k in split_cols}\n",
    "\n",
    "        # add the pianist name to the album name\n",
    "        #  reason here is that two pianists could release an album called \"Solo\"\n",
    "        #  but these are two unique albums!\n",
    "        js_res[\"album_name\"] = f\"{js_res['pianist']} ({js_res['album_name']})\"\n",
    "\n",
    "        js_res[\"setting\"] = \"trio\" if \"data/raw/jtd/\" in str(js) else \"solo\"\n",
    "\n",
    "        split_in.append(js_res)\n",
    "\n",
    "split_df = pd.DataFrame(split_in)"
   ],
   "id": "c60ae212447e964",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:52:30.190309Z",
     "start_time": "2026-02-06T13:48:03.412741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lp_group_split(df, group_col='album_name', train_frac=0.8, val_frac=0.1, test_frac=0.1):\n",
    "    \"\"\"\n",
    "    LP-based group split that:\n",
    "    - Keeps all recordings of a group (album/composition) together\n",
    "    - Approximates 80/10/10 split by number of recordings\n",
    "    - Optionally balances SOLO/TRIO proportions\n",
    "    - Can limit solve time and relative gap\n",
    "    - Assigns split labels in a new column 'split'\n",
    "\n",
    "    Parameters:\n",
    "        df : pandas.DataFrame\n",
    "        group_col : str, column to group by ('album_name' or 'composition_canonic')\n",
    "        train_frac, val_frac, test_frac : float, desired split fractions\n",
    "\n",
    "    Returns:\n",
    "        df : pandas.DataFrame with new column 'split'\n",
    "    \"\"\"\n",
    "    groups = df[group_col].unique()\n",
    "    total_records = len(df)\n",
    "    targets = {'train': total_records * train_frac, 'val': total_records * val_frac, 'test': total_records * test_frac}\n",
    "\n",
    "    stratify_column = \"setting\"\n",
    "\n",
    "    # Records per group\n",
    "    group_sizes = df.groupby(group_col).size().to_dict()\n",
    "\n",
    "    # Stratify counts per group\n",
    "    group_strat_counts = df.groupby(group_col)[stratify_column].value_counts().unstack(fill_value=0).to_dict(orient='index')\n",
    "    strat_levels = df[stratify_column].unique()\n",
    "    global_strat_frac = df[stratify_column].value_counts(normalize=True).to_dict()  # global fraction\n",
    "\n",
    "    # Desired number of stratify types per split\n",
    "    strat_targets = {s: {level: targets[s]*global_strat_frac[level] for level in strat_levels} for s in targets.keys()}\n",
    "\n",
    "    # LP problem\n",
    "    prob = pulp.LpProblem(\"GroupSplit\", pulp.LpMinimize)\n",
    "\n",
    "    # Decision variables: x[group, split] binary\n",
    "    x = pulp.LpVariable.dicts(\"x\", ((g,s) for g in groups for s in targets.keys()), cat='Binary')\n",
    "\n",
    "    # Deviation variables for total records per split\n",
    "    d_total = pulp.LpVariable.dicts(\"d_total\", targets.keys(), lowBound=0)\n",
    "\n",
    "    # Deviation variables for stratify counts per split\n",
    "    d_strat = {s: {level: pulp.LpVariable(f\"d_{s}_{level}\", lowBound=0) for level in strat_levels} for s in targets.keys()}\n",
    "\n",
    "    # 1. Each group assigned to exactly one split\n",
    "    for g in groups:\n",
    "        prob += pulp.lpSum([x[g,s] for s in targets.keys()]) == 1\n",
    "\n",
    "    # 2. Total records deviation constraints\n",
    "    for s in targets.keys():\n",
    "        prob += pulp.lpSum([group_sizes[g]*x[g,s] for g in groups]) - targets[s] <= d_total[s]\n",
    "        prob += targets[s] - pulp.lpSum([group_sizes[g]*x[g,s] for g in groups]) <= d_total[s]\n",
    "\n",
    "    # 3. Stratification deviation constraints\n",
    "    for s in targets.keys():\n",
    "        for level in strat_levels:\n",
    "            prob += pulp.lpSum([group_strat_counts[g].get(level,0)*x[g,s] for g in groups]) - strat_targets[s][level] <= d_strat[s][level]\n",
    "            prob += strat_targets[s][level] - pulp.lpSum([group_strat_counts[g].get(level,0)*x[g,s] for g in groups]) <= d_strat[s][level]\n",
    "\n",
    "    # 4. Pianist coverage constraints\n",
    "    pianists = df['pianist'].unique()\n",
    "    for s in targets.keys():\n",
    "        for p in pianists:\n",
    "            # groups that contain at least one recording by pianist p\n",
    "            groups_with_p = [g for g in groups if p in df[df[group_col]==g]['pianist'].unique()]\n",
    "            # enforce at least one of these groups assigned to split s\n",
    "            prob += pulp.lpSum([x[g,s] for g in groups_with_p]) >= 1\n",
    "\n",
    "    # 5. Objective function: minimize total deviation\n",
    "    prob += pulp.lpSum([d_total[s] for s in targets.keys()]) + pulp.lpSum([d_strat[s][level] for s in targets.keys() for level in strat_levels])\n",
    "\n",
    "    # 6. Solve\n",
    "    solver = pulp.PULP_CBC_CMD(timeLimit=120, gapRel=0.02, msg=True)\n",
    "    prob.solve(solver)\n",
    "\n",
    "    # Extract assignment\n",
    "    assignment = {s: [] for s in targets.keys()}\n",
    "    for g in groups:\n",
    "        for s in targets.keys():\n",
    "            if pulp.value(x[g,s]) > 0.5:\n",
    "                assignment[s].append(g)\n",
    "\n",
    "    # Assign split column\n",
    "    df['split'] = None\n",
    "    for s, group_list in assignment.items():\n",
    "        df.loc[df[group_col].isin(group_list), 'split'] = s\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "album_df = lp_group_split(split_df, group_col='album_name')\n",
    "comp_df = lp_group_split(split_df, group_col='composition_canonic')"
   ],
   "id": "17953366687f62d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/huw-cheston/.cache/pypoetry/virtualenvs/deep-pianist-identification-2Pg5O36G-py3.12/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/2f2fa1d655514f97812b38913cc8578f-pulp.mps -sec 120 -ratio 0.02 -timeMode elapsed -branch -printingOptions all -solution /tmp/2f2fa1d655514f97812b38913cc8578f-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 442 COLUMNS\n",
      "At line 9098 RHS\n",
      "At line 9536 BOUNDS\n",
      "At line 10614 ENDATA\n",
      "Problem MODEL has 437 rows, 1086 columns and 6492 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 120\n",
      "ratioGap was changed from 0 to 0.02\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0 - 0.00 seconds\n",
      "Cgl0004I processed model has 437 rows, 1086 columns (1077 integer (1077 of which binary)) and 6492 elements\n",
      "Cbc0038I Initial state - 8 integers unsatisfied sum - 2.54121\n",
      "Cbc0038I Pass   1: suminf.    0.00000 (0) obj. 47.4 iterations 226\n",
      "Cbc0038I Solution found of 47.4\n",
      "Cbc0038I Relaxing continuous gives 47.4\n",
      "Cbc0038I Before mini branch and bound, 1069 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 18 rows 13 columns\n",
      "Cbc0038I Mini branch and bound improved solution from 47.4 to 41.6 (0.02 seconds)\n",
      "Cbc0038I Round again with cutoff of 37.44\n",
      "Cbc0038I Pass   2: suminf.    0.19154 (2) obj. 37.44 iterations 98\n",
      "Cbc0038I Pass   3: suminf.    0.82588 (2) obj. 37.44 iterations 176\n",
      "Cbc0038I Pass   4: suminf.    0.61706 (2) obj. 37.44 iterations 138\n",
      "Cbc0038I Pass   5: suminf.    2.06582 (10) obj. 37.44 iterations 184\n",
      "Cbc0038I Pass   6: suminf.    0.67400 (3) obj. 37.44 iterations 131\n",
      "Cbc0038I Pass   7: suminf.    0.02900 (2) obj. 37.44 iterations 174\n",
      "Cbc0038I Pass   8: suminf.    0.01706 (2) obj. 37.44 iterations 76\n",
      "Cbc0038I Pass   9: suminf.    0.78000 (2) obj. 37.44 iterations 43\n",
      "Cbc0038I Pass  10: suminf.    2.03616 (8) obj. 37.44 iterations 210\n",
      "Cbc0038I Pass  11: suminf.    0.26118 (2) obj. 37.44 iterations 160\n",
      "Cbc0038I Pass  12: suminf.    0.88588 (2) obj. 37.44 iterations 124\n",
      "Cbc0038I Pass  13: suminf.    1.74172 (6) obj. 37.44 iterations 221\n",
      "Cbc0038I Pass  14: suminf.    0.31727 (2) obj. 37.44 iterations 96\n",
      "Cbc0038I Pass  15: suminf.    0.49941 (2) obj. 37.44 iterations 183\n",
      "Cbc0038I Pass  16: suminf.    0.91118 (2) obj. 37.44 iterations 167\n",
      "Cbc0038I Pass  17: suminf.    0.99754 (6) obj. 37.44 iterations 243\n",
      "Cbc0038I Pass  18: suminf.    0.00000 (0) obj. 37.44 iterations 255\n",
      "Cbc0038I Solution found of 37.44\n",
      "Cbc0038I Relaxing continuous gives 17.2\n",
      "Cbc0038I Before mini branch and bound, 702 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 78 rows 198 columns\n",
      "Cbc0038I Mini branch and bound improved solution from 17.2 to 3.8 (0.11 seconds)\n",
      "Cbc0038I Round again with cutoff of 3.03999\n",
      "Cbc0038I Pass  19: suminf.    1.35501 (8) obj. 3.03999 iterations 60\n",
      "Cbc0038I Pass  20: suminf.    1.12706 (6) obj. 3.03999 iterations 196\n",
      "Cbc0038I Pass  21: suminf.    1.06025 (7) obj. 3.03999 iterations 103\n",
      "Cbc0038I Pass  22: suminf.    1.38279 (7) obj. 3.03999 iterations 84\n",
      "Cbc0038I Pass  23: suminf.    1.09735 (7) obj. 3.03999 iterations 86\n",
      "Cbc0038I Pass  24: suminf.    2.57733 (10) obj. 3.03999 iterations 262\n",
      "Cbc0038I Pass  25: suminf.    1.05686 (7) obj. 3.03999 iterations 81\n",
      "Cbc0038I Pass  26: suminf.    1.43425 (7) obj. 3.03999 iterations 201\n",
      "Cbc0038I Pass  27: suminf.    0.53176 (6) obj. 3.03999 iterations 213\n",
      "Cbc0038I Pass  28: suminf.    0.62118 (6) obj. 3.03999 iterations 76\n",
      "Cbc0038I Pass  29: suminf.    3.19949 (10) obj. 3.03999 iterations 232\n",
      "Cbc0038I Pass  30: suminf.    0.75417 (7) obj. 3.03999 iterations 187\n",
      "Cbc0038I Pass  31: suminf.    0.53569 (7) obj. 3.03999 iterations 32\n",
      "Cbc0038I Pass  32: suminf.    1.20235 (7) obj. 3.03999 iterations 197\n",
      "Cbc0038I Pass  33: suminf.    1.20235 (7) obj. 3.03999 iterations 29\n",
      "Cbc0038I Pass  34: suminf.    0.60275 (7) obj. 3.03999 iterations 186\n",
      "Cbc0038I Pass  35: suminf.    3.51521 (10) obj. 3.03999 iterations 279\n",
      "Cbc0038I Pass  36: suminf.    1.34000 (7) obj. 3.03999 iterations 172\n",
      "Cbc0038I Pass  37: suminf.    1.34000 (7) obj. 3.03999 iterations 4\n",
      "Cbc0038I Pass  38: suminf.    1.71176 (6) obj. 3.03999 iterations 140\n",
      "Cbc0038I Pass  39: suminf.    1.66706 (6) obj. 3.03999 iterations 137\n",
      "Cbc0038I Pass  40: suminf.    1.70000 (6) obj. 3.03999 iterations 194\n",
      "Cbc0038I Pass  41: suminf.    1.65529 (6) obj. 3.03999 iterations 161\n",
      "Cbc0038I Pass  42: suminf.    1.71176 (6) obj. 3.03999 iterations 178\n",
      "Cbc0038I Pass  43: suminf.    0.89546 (8) obj. 3.03999 iterations 239\n",
      "Cbc0038I Pass  44: suminf.    0.26000 (7) obj. 3.03999 iterations 130\n",
      "Cbc0038I Pass  45: suminf.    0.93244 (7) obj. 3.03999 iterations 148\n",
      "Cbc0038I Pass  46: suminf.    0.57653 (7) obj. 3.03999 iterations 123\n",
      "Cbc0038I Pass  47: suminf.    1.37230 (7) obj. 3.03999 iterations 179\n",
      "Cbc0038I Pass  48: suminf.    0.82588 (6) obj. 3.03999 iterations 124\n",
      "Cbc0038I No solution found this major pass\n",
      "Cbc0038I Before mini branch and bound, 679 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 78 rows 200 columns\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.23 seconds)\n",
      "Cbc0038I After 0.23 seconds - Feasibility pump exiting with objective of 3.8 - took 0.21 seconds\n",
      "Cbc0012I Integer solution of 3.8 found by feasibility pump after 0 iterations and 0 nodes (0.23 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 20 rows 29 columns\n",
      "Cbc0031I 19 added rows had average density of 210.78947\n",
      "Cbc0013I At root node, 19 cuts changed objective from 0 to 1.24 in 12 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.007 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 1 (Gomory) - 86 row cuts average 528.4 elements, 0 column cuts (0 active)  in 0.009 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.004 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 273 row cuts average 166.7 elements, 0 column cuts (0 active)  in 0.020 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.007 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 6 (TwoMirCuts) - 109 row cuts average 315.4 elements, 0 column cuts (0 active)  in 0.010 seconds - new frequency is 1\n",
      "Cbc0010I After 0 nodes, 1 on tree, 3.8 best solution, best possible 1.24 (0.39 seconds)\n",
      "Cbc0012I Integer solution of 1.6 found by DiveCoefficient after 475 iterations and 2 nodes (0.42 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 20 rows 19 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 21 rows 26 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 19 rows 28 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 19 rows 26 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 19 rows 28 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 20 rows 29 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 20 rows 29 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 22 rows 39 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 20 rows 30 columns\n",
      "Cbc0010I After 1000 nodes, 509 on tree, 1.6 best solution, best possible 1.24 (4.37 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 35 rows 74 columns\n",
      "Cbc0010I After 2000 nodes, 607 on tree, 1.6 best solution, best possible 1.24 (8.35 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 33 rows 67 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 35 rows 73 columns\n",
      "Cbc0010I After 3000 nodes, 616 on tree, 1.6 best solution, best possible 1.24 (12.76 seconds)\n",
      "Cbc0010I After 4000 nodes, 595 on tree, 1.6 best solution, best possible 1.24 (17.39 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 37 rows 77 columns\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 31 rows 67 columns\n",
      "Cbc0010I After 5000 nodes, 593 on tree, 1.6 best solution, best possible 1.24 (21.78 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 28 rows 56 columns\n",
      "Cbc0010I After 6000 nodes, 633 on tree, 1.6 best solution, best possible 1.24 (26.02 seconds)\n",
      "Cbc0010I After 7000 nodes, 721 on tree, 1.6 best solution, best possible 1.24 (29.07 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 27 rows 53 columns\n",
      "Cbc0010I After 8000 nodes, 628 on tree, 1.6 best solution, best possible 1.24 (33.13 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 30 rows 60 columns\n",
      "Cbc0010I After 9000 nodes, 630 on tree, 1.6 best solution, best possible 1.24 (37.38 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 36 rows 75 columns\n",
      "Cbc0010I After 10000 nodes, 637 on tree, 1.6 best solution, best possible 1.24 (41.34 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 37 rows 77 columns\n",
      "Cbc0010I After 11000 nodes, 631 on tree, 1.6 best solution, best possible 1.24 (45.27 seconds)\n",
      "Cbc0010I After 12000 nodes, 1137 on tree, 1.6 best solution, best possible 1.24 (48.83 seconds)\n",
      "Cbc0010I After 13000 nodes, 1625 on tree, 1.6 best solution, best possible 1.24 (52.39 seconds)\n",
      "Cbc0010I After 14000 nodes, 1683 on tree, 1.6 best solution, best possible 1.24 (55.82 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 21 rows 31 columns\n",
      "Cbc0010I After 15000 nodes, 2209 on tree, 1.6 best solution, best possible 1.24 (59.25 seconds)\n",
      "Cbc0010I After 16000 nodes, 2707 on tree, 1.6 best solution, best possible 1.24 (62.51 seconds)\n",
      "Cbc0010I After 17000 nodes, 3176 on tree, 1.6 best solution, best possible 1.24 (65.93 seconds)\n",
      "Cbc0010I After 18000 nodes, 3237 on tree, 1.6 best solution, best possible 1.24 (69.50 seconds)\n",
      "Cbc0010I After 19000 nodes, 3745 on tree, 1.6 best solution, best possible 1.24 (72.82 seconds)\n",
      "Cbc0010I After 20000 nodes, 4241 on tree, 1.6 best solution, best possible 1.24 (76.09 seconds)\n",
      "Cbc0010I After 21000 nodes, 4759 on tree, 1.6 best solution, best possible 1.24 (79.55 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 23 rows 47 columns\n",
      "Cbc0010I After 22000 nodes, 4807 on tree, 1.6 best solution, best possible 1.24 (82.59 seconds)\n",
      "Cbc0010I After 23000 nodes, 5275 on tree, 1.6 best solution, best possible 1.24 (86.05 seconds)\n",
      "Cbc0010I After 24000 nodes, 5772 on tree, 1.6 best solution, best possible 1.24 (89.51 seconds)\n",
      "Cbc0010I After 25000 nodes, 6198 on tree, 1.6 best solution, best possible 1.24 (93.15 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 39 rows 81 columns\n",
      "Cbc0010I After 26000 nodes, 6209 on tree, 1.6 best solution, best possible 1.24 (97.03 seconds)\n",
      "Cbc0010I After 27000 nodes, 6564 on tree, 1.6 best solution, best possible 1.24 (100.93 seconds)\n",
      "Cbc0010I After 28000 nodes, 6869 on tree, 1.6 best solution, best possible 1.24 (104.51 seconds)\n",
      "Cbc0038I Full problem 437 rows 1086 columns, reduced to 21 rows 31 columns\n",
      "Cbc0010I After 29000 nodes, 7178 on tree, 1.6 best solution, best possible 1.24 (108.34 seconds)\n",
      "Cbc0010I After 30000 nodes, 7178 on tree, 1.6 best solution, best possible 1.24 (111.86 seconds)\n",
      "Cbc0010I After 31000 nodes, 7463 on tree, 1.6 best solution, best possible 1.24 (115.44 seconds)\n",
      "Cbc0010I After 32000 nodes, 7839 on tree, 1.6 best solution, best possible 1.24 (119.21 seconds)\n",
      "Cbc0020I Exiting on maximum time\n",
      "Cbc0005I Partial search - best objective 1.6 (best possible 1.24), took 727373 iterations and 32215 nodes (120.15 seconds)\n",
      "Cbc0032I Strong branching done 12550 times (68923 iterations), fathomed 1058 nodes and fixed 758 variables\n",
      "Cbc0035I Maximum depth 439, 90532 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 0 to 1.24\n",
      "Probing was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.007 seconds)\n",
      "Gomory was tried 12 times and created 86 cuts of which 0 were active after adding rounds of cuts (0.009 seconds)\n",
      "Knapsack was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.004 seconds)\n",
      "Clique was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 30851 times and created 357289 cuts of which 0 were active after adding rounds of cuts (39.052 seconds)\n",
      "FlowCover was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.007 seconds)\n",
      "TwoMirCuts was tried 30851 times and created 20629 cuts of which 0 were active after adding rounds of cuts (5.106 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Stopped on time limit\n",
      "\n",
      "Objective value:                1.60000000\n",
      "Lower bound:                    1.240\n",
      "Gap:                            0.29\n",
      "Enumerated nodes:               32215\n",
      "Total iterations:               727373\n",
      "Time (CPU seconds):             118.57\n",
      "Time (Wallclock seconds):       120.16\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       118.58   (Wallclock seconds):       120.17\n",
      "\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/huw-cheston/.cache/pypoetry/virtualenvs/deep-pianist-identification-2Pg5O36G-py3.12/lib/python3.12/site-packages/pulp/apis/../solverdir/cbc/linux/i64/cbc /tmp/1d61852fa4b545a3aa3b16cad8484805-pulp.mps -sec 120 -ratio 0.02 -timeMode elapsed -branch -printingOptions all -solution /tmp/1d61852fa4b545a3aa3b16cad8484805-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 997 COLUMNS\n",
      "At line 24548 RHS\n",
      "At line 25541 BOUNDS\n",
      "At line 28284 ENDATA\n",
      "Problem MODEL has 992 rows, 2751 columns and 18057 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "seconds was changed from 1e+100 to 120\n",
      "ratioGap was changed from 0 to 0.02\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 0 - 0.02 seconds\n",
      "Cgl0004I processed model has 992 rows, 2751 columns (2742 integer (2742 of which binary)) and 18057 elements\n",
      "Cbc0038I Initial state - 8 integers unsatisfied sum - 2.6\n",
      "Cbc0038I Pass   1: suminf.    0.00000 (0) obj. 3.8 iterations 366\n",
      "Cbc0038I Solution found of 3.8\n",
      "Cbc0038I Relaxing continuous gives 3.8\n",
      "Cbc0038I Before mini branch and bound, 2734 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 13 columns\n",
      "Cbc0038I Mini branch and bound improved solution from 3.8 to 3.8 (0.06 seconds)\n",
      "Cbc0038I Round again with cutoff of 3.41999\n",
      "Cbc0038I Pass   2: suminf.    0.00826 (2) obj. 3.41999 iterations 180\n",
      "Cbc0038I Pass   3: suminf.    0.10056 (2) obj. 3.41999 iterations 353\n",
      "Cbc0038I Pass   4: suminf.    1.25500 (6) obj. 3.41999 iterations 316\n",
      "Cbc0038I Pass   5: suminf.    0.00000 (0) obj. 3.41999 iterations 188\n",
      "Cbc0038I Solution found of 3.41999\n",
      "Cbc0038I Relaxing continuous gives 1.6\n",
      "Cbc0038I Before mini branch and bound, 2566 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 23 columns\n",
      "Cbc0038I Mini branch and bound improved solution from 1.6 to 1.6 (0.13 seconds)\n",
      "Cbc0038I Round again with cutoff of 1.27999\n",
      "Cbc0038I Pass   6: suminf.    0.06133 (4) obj. 1.27999 iterations 10\n",
      "Cbc0038I Pass   7: suminf.    0.10367 (4) obj. 1.27999 iterations 331\n",
      "Cbc0038I Pass   8: suminf.    1.04000 (8) obj. 1.27999 iterations 455\n",
      "Cbc0038I Pass   9: suminf.    0.04000 (2) obj. 1.27999 iterations 455\n",
      "Cbc0038I Pass  10: suminf.    0.44467 (4) obj. 1.27999 iterations 68\n",
      "Cbc0038I Pass  11: suminf.    0.48700 (4) obj. 1.27999 iterations 384\n",
      "Cbc0038I Pass  12: suminf.    2.16000 (8) obj. 1.27999 iterations 470\n",
      "Cbc0038I Pass  13: suminf.    0.13286 (2) obj. 1.27999 iterations 140\n",
      "Cbc0038I Pass  14: suminf.    1.28968 (4) obj. 1.27999 iterations 378\n",
      "Cbc0038I Pass  15: suminf.    1.36839 (4) obj. 1.27999 iterations 259\n",
      "Cbc0038I Pass  16: suminf.    2.57500 (8) obj. 1.27999 iterations 322\n",
      "Cbc0038I Pass  17: suminf.    0.50087 (5) obj. 1.27999 iterations 284\n",
      "Cbc0038I Pass  18: suminf.    1.00901 (7) obj. 1.27999 iterations 538\n",
      "Cbc0038I Pass  19: suminf.    2.09334 (8) obj. 1.27999 iterations 396\n",
      "Cbc0038I Pass  20: suminf.    0.40667 (6) obj. 1.27999 iterations 241\n",
      "Cbc0038I Pass  21: suminf.    0.87800 (6) obj. 1.27999 iterations 309\n",
      "Cbc0038I Pass  22: suminf.    0.94200 (6) obj. 1.27999 iterations 180\n",
      "Cbc0038I Pass  23: suminf.    2.74001 (8) obj. 1.27999 iterations 366\n",
      "Cbc0038I Pass  24: suminf.    0.87000 (4) obj. 1.27999 iterations 193\n",
      "Cbc0038I Pass  25: suminf.    0.84467 (4) obj. 1.27999 iterations 445\n",
      "Cbc0038I Pass  26: suminf.    0.88700 (4) obj. 1.27999 iterations 442\n",
      "Cbc0038I Pass  27: suminf.    3.00000 (8) obj. 1.27999 iterations 395\n",
      "Cbc0038I Pass  28: suminf.    0.58812 (6) obj. 1.27999 iterations 352\n",
      "Cbc0038I Pass  29: suminf.    0.84644 (7) obj. 1.27999 iterations 347\n",
      "Cbc0038I Pass  30: suminf.    0.51981 (4) obj. 1.27999 iterations 244\n",
      "Cbc0038I Pass  31: suminf.    0.56831 (4) obj. 1.27999 iterations 495\n",
      "Cbc0038I Pass  32: suminf.    0.80000 (8) obj. 1.27999 iterations 462\n",
      "Cbc0038I Pass  33: suminf.    0.03945 (4) obj. 1.27999 iterations 414\n",
      "Cbc0038I Pass  34: suminf.    0.36356 (4) obj. 1.27999 iterations 140\n",
      "Cbc0038I Pass  35: suminf.    0.36356 (4) obj. 1.27999 iterations 0\n",
      "Cbc0038I No solution found this major pass\n",
      "Cbc0038I Before mini branch and bound, 1914 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 98 rows 282 columns\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.48 seconds)\n",
      "Cbc0038I After 0.48 seconds - Feasibility pump exiting with objective of 1.6 - took 0.43 seconds\n",
      "Cbc0012I Integer solution of 1.6 found by feasibility pump after 0 iterations and 0 nodes (0.48 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 21 columns\n",
      "Cbc0031I 14 added rows had average density of 777.92857\n",
      "Cbc0013I At root node, 14 cuts changed objective from 0 to 1.419952 in 12 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.022 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 1 (Gomory) - 50 row cuts average 1641.5 elements, 0 column cuts (0 active)  in 0.026 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.011 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.001 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 99 row cuts average 528.1 elements, 0 column cuts (0 active)  in 0.051 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.027 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 6 (TwoMirCuts) - 2 row cuts average 423.0 elements, 0 column cuts (0 active)  in 0.014 seconds - new frequency is -100\n",
      "Cbc0010I After 0 nodes, 1 on tree, 1.6 best solution, best possible 1.419952 (0.86 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 24 columns\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 26 columns\n",
      "Cbc0010I After 100 nodes, 55 on tree, 1.6 best solution, best possible 1.419952 (2.81 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 21 rows 32 columns\n",
      "Cbc0010I After 200 nodes, 107 on tree, 1.6 best solution, best possible 1.419952 (4.50 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 20 rows 29 columns\n",
      "Cbc0010I After 300 nodes, 158 on tree, 1.6 best solution, best possible 1.419952 (5.95 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 20 rows 31 columns\n",
      "Cbc0010I After 400 nodes, 207 on tree, 1.6 best solution, best possible 1.419952 (7.54 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 29 columns\n",
      "Cbc0010I After 500 nodes, 257 on tree, 1.6 best solution, best possible 1.419952 (8.78 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 20 rows 34 columns\n",
      "Cbc0010I After 600 nodes, 308 on tree, 1.6 best solution, best possible 1.419952 (9.64 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 26 columns\n",
      "Cbc0010I After 700 nodes, 358 on tree, 1.6 best solution, best possible 1.419952 (10.44 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 26 columns\n",
      "Cbc0010I After 800 nodes, 407 on tree, 1.6 best solution, best possible 1.419952 (11.81 seconds)\n",
      "Cbc0010I After 900 nodes, 458 on tree, 1.6 best solution, best possible 1.419952 (13.08 seconds)\n",
      "Cbc0010I After 1000 nodes, 511 on tree, 1.6 best solution, best possible 1.419952 (14.78 seconds)\n",
      "Cbc0010I After 1100 nodes, 609 on tree, 1.6 best solution, best possible 1.419952 (15.64 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 26 columns\n",
      "Cbc0010I After 1200 nodes, 709 on tree, 1.6 best solution, best possible 1.419952 (16.38 seconds)\n",
      "Cbc0010I After 1300 nodes, 809 on tree, 1.6 best solution, best possible 1.419952 (17.05 seconds)\n",
      "Cbc0010I After 1400 nodes, 909 on tree, 1.6 best solution, best possible 1.419952 (17.69 seconds)\n",
      "Cbc0010I After 1500 nodes, 1009 on tree, 1.6 best solution, best possible 1.419952 (18.20 seconds)\n",
      "Cbc0010I After 1600 nodes, 1109 on tree, 1.6 best solution, best possible 1.419952 (18.73 seconds)\n",
      "Cbc0010I After 1700 nodes, 1209 on tree, 1.6 best solution, best possible 1.419952 (19.18 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 25 columns\n",
      "Cbc0010I After 1800 nodes, 1309 on tree, 1.6 best solution, best possible 1.419952 (19.63 seconds)\n",
      "Cbc0010I After 1900 nodes, 1409 on tree, 1.6 best solution, best possible 1.419952 (19.99 seconds)\n",
      "Cbc0010I After 2000 nodes, 1509 on tree, 1.6 best solution, best possible 1.419952 (20.35 seconds)\n",
      "Cbc0010I After 2100 nodes, 1558 on tree, 1.6 best solution, best possible 1.419952 (20.70 seconds)\n",
      "Cbc0010I After 2200 nodes, 1602 on tree, 1.6 best solution, best possible 1.419952 (21.30 seconds)\n",
      "Cbc0010I After 2300 nodes, 1583 on tree, 1.6 best solution, best possible 1.419952 (21.68 seconds)\n",
      "Cbc0010I After 2400 nodes, 1596 on tree, 1.6 best solution, best possible 1.419952 (22.08 seconds)\n",
      "Cbc0010I After 2500 nodes, 1609 on tree, 1.6 best solution, best possible 1.419952 (22.47 seconds)\n",
      "Cbc0010I After 2600 nodes, 1595 on tree, 1.6 best solution, best possible 1.419952 (22.74 seconds)\n",
      "Cbc0010I After 2700 nodes, 1678 on tree, 1.6 best solution, best possible 1.419952 (22.97 seconds)\n",
      "Cbc0010I After 2800 nodes, 1581 on tree, 1.6 best solution, best possible 1.419952 (23.06 seconds)\n",
      "Cbc0010I After 2900 nodes, 1598 on tree, 1.6 best solution, best possible 1.419952 (23.65 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 25 columns\n",
      "Cbc0010I After 3000 nodes, 1611 on tree, 1.6 best solution, best possible 1.419952 (24.20 seconds)\n",
      "Cbc0010I After 3100 nodes, 1599 on tree, 1.6 best solution, best possible 1.419952 (24.57 seconds)\n",
      "Cbc0010I After 3200 nodes, 1585 on tree, 1.6 best solution, best possible 1.419952 (24.94 seconds)\n",
      "Cbc0010I After 3300 nodes, 1632 on tree, 1.6 best solution, best possible 1.419952 (25.34 seconds)\n",
      "Cbc0010I After 3400 nodes, 1629 on tree, 1.6 best solution, best possible 1.419952 (25.64 seconds)\n",
      "Cbc0010I After 3500 nodes, 1615 on tree, 1.6 best solution, best possible 1.419952 (25.90 seconds)\n",
      "Cbc0010I After 3600 nodes, 1612 on tree, 1.6 best solution, best possible 1.419952 (26.20 seconds)\n",
      "Cbc0010I After 3700 nodes, 1629 on tree, 1.6 best solution, best possible 1.419952 (26.54 seconds)\n",
      "Cbc0010I After 3800 nodes, 1604 on tree, 1.6 best solution, best possible 1.419952 (26.77 seconds)\n",
      "Cbc0010I After 3900 nodes, 1605 on tree, 1.6 best solution, best possible 1.419952 (27.11 seconds)\n",
      "Cbc0010I After 4000 nodes, 1597 on tree, 1.6 best solution, best possible 1.419952 (27.44 seconds)\n",
      "Cbc0010I After 4100 nodes, 1588 on tree, 1.6 best solution, best possible 1.419952 (27.77 seconds)\n",
      "Cbc0010I After 4200 nodes, 1590 on tree, 1.6 best solution, best possible 1.419952 (28.15 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 28 columns\n",
      "Cbc0010I After 4300 nodes, 1605 on tree, 1.6 best solution, best possible 1.419952 (28.57 seconds)\n",
      "Cbc0010I After 4400 nodes, 1598 on tree, 1.6 best solution, best possible 1.419952 (28.95 seconds)\n",
      "Cbc0010I After 4500 nodes, 1598 on tree, 1.6 best solution, best possible 1.419952 (29.34 seconds)\n",
      "Cbc0010I After 4600 nodes, 1602 on tree, 1.6 best solution, best possible 1.419952 (29.73 seconds)\n",
      "Cbc0010I After 4700 nodes, 1606 on tree, 1.6 best solution, best possible 1.419952 (30.13 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 25 columns\n",
      "Cbc0010I After 4800 nodes, 1611 on tree, 1.6 best solution, best possible 1.419952 (30.63 seconds)\n",
      "Cbc0010I After 4900 nodes, 1597 on tree, 1.6 best solution, best possible 1.419952 (30.93 seconds)\n",
      "Cbc0010I After 5000 nodes, 1622 on tree, 1.6 best solution, best possible 1.419952 (31.40 seconds)\n",
      "Cbc0010I After 5100 nodes, 1719 on tree, 1.6 best solution, best possible 1.419952 (31.89 seconds)\n",
      "Cbc0010I After 5200 nodes, 1819 on tree, 1.6 best solution, best possible 1.419952 (32.57 seconds)\n",
      "Cbc0010I After 5300 nodes, 1919 on tree, 1.6 best solution, best possible 1.419952 (33.58 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 26 columns\n",
      "Cbc0010I After 5400 nodes, 2019 on tree, 1.6 best solution, best possible 1.419952 (34.18 seconds)\n",
      "Cbc0010I After 5500 nodes, 2119 on tree, 1.6 best solution, best possible 1.419952 (34.50 seconds)\n",
      "Cbc0010I After 5600 nodes, 2219 on tree, 1.6 best solution, best possible 1.419952 (34.80 seconds)\n",
      "Cbc0010I After 5700 nodes, 2315 on tree, 1.6 best solution, best possible 1.419952 (35.07 seconds)\n",
      "Cbc0010I After 5800 nodes, 2409 on tree, 1.6 best solution, best possible 1.419952 (35.40 seconds)\n",
      "Cbc0010I After 5900 nodes, 2493 on tree, 1.6 best solution, best possible 1.419952 (35.63 seconds)\n",
      "Cbc0010I After 6000 nodes, 2506 on tree, 1.6 best solution, best possible 1.419952 (36.22 seconds)\n",
      "Cbc0010I After 6100 nodes, 2508 on tree, 1.6 best solution, best possible 1.419952 (36.58 seconds)\n",
      "Cbc0010I After 6200 nodes, 2504 on tree, 1.6 best solution, best possible 1.419952 (36.96 seconds)\n",
      "Cbc0010I After 6300 nodes, 2499 on tree, 1.6 best solution, best possible 1.419952 (37.43 seconds)\n",
      "Cbc0010I After 6400 nodes, 2492 on tree, 1.6 best solution, best possible 1.419952 (37.75 seconds)\n",
      "Cbc0010I After 6500 nodes, 2494 on tree, 1.6 best solution, best possible 1.419952 (38.12 seconds)\n",
      "Cbc0010I After 6600 nodes, 2494 on tree, 1.6 best solution, best possible 1.419952 (38.46 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 29 columns\n",
      "Cbc0010I After 6700 nodes, 2488 on tree, 1.6 best solution, best possible 1.419952 (38.80 seconds)\n",
      "Cbc0010I After 6800 nodes, 2487 on tree, 1.6 best solution, best possible 1.419952 (39.15 seconds)\n",
      "Cbc0010I After 6900 nodes, 2490 on tree, 1.6 best solution, best possible 1.419952 (39.50 seconds)\n",
      "Cbc0010I After 7000 nodes, 2483 on tree, 1.6 best solution, best possible 1.419952 (39.80 seconds)\n",
      "Cbc0010I After 7100 nodes, 2488 on tree, 1.6 best solution, best possible 1.419952 (40.14 seconds)\n",
      "Cbc0010I After 7200 nodes, 2490 on tree, 1.6 best solution, best possible 1.419952 (40.47 seconds)\n",
      "Cbc0010I After 7300 nodes, 2478 on tree, 1.6 best solution, best possible 1.419952 (40.79 seconds)\n",
      "Cbc0010I After 7400 nodes, 2480 on tree, 1.6 best solution, best possible 1.419952 (41.13 seconds)\n",
      "Cbc0010I After 7500 nodes, 2476 on tree, 1.6 best solution, best possible 1.419952 (41.47 seconds)\n",
      "Cbc0010I After 7600 nodes, 2475 on tree, 1.6 best solution, best possible 1.419952 (41.74 seconds)\n",
      "Cbc0010I After 7700 nodes, 2473 on tree, 1.6 best solution, best possible 1.419952 (42.09 seconds)\n",
      "Cbc0010I After 7800 nodes, 2474 on tree, 1.6 best solution, best possible 1.419952 (42.47 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 25 columns\n",
      "Cbc0010I After 7900 nodes, 2482 on tree, 1.6 best solution, best possible 1.419952 (42.83 seconds)\n",
      "Cbc0010I After 8000 nodes, 2471 on tree, 1.6 best solution, best possible 1.419952 (43.19 seconds)\n",
      "Cbc0010I After 8100 nodes, 2481 on tree, 1.6 best solution, best possible 1.419952 (43.53 seconds)\n",
      "Cbc0010I After 8200 nodes, 2478 on tree, 1.6 best solution, best possible 1.419952 (43.88 seconds)\n",
      "Cbc0010I After 8300 nodes, 2470 on tree, 1.6 best solution, best possible 1.419952 (44.25 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 29 columns\n",
      "Cbc0010I After 8400 nodes, 2481 on tree, 1.6 best solution, best possible 1.419952 (44.79 seconds)\n",
      "Cbc0010I After 8500 nodes, 2472 on tree, 1.6 best solution, best possible 1.419952 (45.21 seconds)\n",
      "Cbc0010I After 8600 nodes, 2467 on tree, 1.6 best solution, best possible 1.419952 (45.61 seconds)\n",
      "Cbc0010I After 8700 nodes, 2468 on tree, 1.6 best solution, best possible 1.419952 (45.96 seconds)\n",
      "Cbc0010I After 8800 nodes, 2468 on tree, 1.6 best solution, best possible 1.419952 (46.29 seconds)\n",
      "Cbc0010I After 8900 nodes, 2462 on tree, 1.6 best solution, best possible 1.419952 (46.63 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 23 columns\n",
      "Cbc0010I After 9000 nodes, 2459 on tree, 1.6 best solution, best possible 1.419952 (46.93 seconds)\n",
      "Cbc0010I After 9100 nodes, 2557 on tree, 1.6 best solution, best possible 1.419952 (47.66 seconds)\n",
      "Cbc0010I After 9200 nodes, 2657 on tree, 1.6 best solution, best possible 1.419952 (48.29 seconds)\n",
      "Cbc0010I After 9300 nodes, 2757 on tree, 1.6 best solution, best possible 1.419952 (48.81 seconds)\n",
      "Cbc0010I After 9400 nodes, 2857 on tree, 1.6 best solution, best possible 1.419952 (49.43 seconds)\n",
      "Cbc0010I After 9500 nodes, 2957 on tree, 1.6 best solution, best possible 1.419952 (49.88 seconds)\n",
      "Cbc0010I After 9600 nodes, 3053 on tree, 1.6 best solution, best possible 1.419952 (50.31 seconds)\n",
      "Cbc0010I After 9700 nodes, 3085 on tree, 1.6 best solution, best possible 1.419952 (50.93 seconds)\n",
      "Cbc0010I After 9800 nodes, 3086 on tree, 1.6 best solution, best possible 1.419952 (51.47 seconds)\n",
      "Cbc0010I After 9900 nodes, 3085 on tree, 1.6 best solution, best possible 1.419952 (51.98 seconds)\n",
      "Cbc0010I After 10000 nodes, 3086 on tree, 1.6 best solution, best possible 1.419952 (52.46 seconds)\n",
      "Cbc0010I After 10100 nodes, 3082 on tree, 1.6 best solution, best possible 1.419952 (52.92 seconds)\n",
      "Cbc0010I After 10200 nodes, 3085 on tree, 1.6 best solution, best possible 1.419952 (53.44 seconds)\n",
      "Cbc0010I After 10300 nodes, 3083 on tree, 1.6 best solution, best possible 1.419952 (54.05 seconds)\n",
      "Cbc0010I After 10400 nodes, 3085 on tree, 1.6 best solution, best possible 1.419952 (54.53 seconds)\n",
      "Cbc0010I After 10500 nodes, 3082 on tree, 1.6 best solution, best possible 1.419952 (55.04 seconds)\n",
      "Cbc0010I After 10600 nodes, 3084 on tree, 1.6 best solution, best possible 1.419952 (55.50 seconds)\n",
      "Cbc0010I After 10700 nodes, 3085 on tree, 1.6 best solution, best possible 1.419952 (56.14 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 18 rows 25 columns\n",
      "Cbc0010I After 10800 nodes, 3083 on tree, 1.6 best solution, best possible 1.419952 (56.60 seconds)\n",
      "Cbc0010I After 10900 nodes, 3082 on tree, 1.6 best solution, best possible 1.419952 (57.04 seconds)\n",
      "Cbc0010I After 11000 nodes, 3084 on tree, 1.6 best solution, best possible 1.419952 (57.55 seconds)\n",
      "Cbc0010I After 11100 nodes, 3084 on tree, 1.6 best solution, best possible 1.419952 (58.75 seconds)\n",
      "Cbc0010I After 11200 nodes, 3087 on tree, 1.6 best solution, best possible 1.419952 (60.27 seconds)\n",
      "Cbc0010I After 11300 nodes, 3145 on tree, 1.6 best solution, best possible 1.419952 (61.64 seconds)\n",
      "Cbc0010I After 11400 nodes, 3201 on tree, 1.6 best solution, best possible 1.419952 (62.74 seconds)\n",
      "Cbc0010I After 11500 nodes, 3258 on tree, 1.6 best solution, best possible 1.419952 (63.78 seconds)\n",
      "Cbc0010I After 11600 nodes, 3315 on tree, 1.6 best solution, best possible 1.419952 (64.72 seconds)\n",
      "Cbc0010I After 11700 nodes, 3372 on tree, 1.6 best solution, best possible 1.419952 (65.58 seconds)\n",
      "Cbc0010I After 11800 nodes, 3430 on tree, 1.6 best solution, best possible 1.419952 (66.53 seconds)\n",
      "Cbc0010I After 11900 nodes, 3487 on tree, 1.6 best solution, best possible 1.419952 (67.37 seconds)\n",
      "Cbc0010I After 12000 nodes, 3545 on tree, 1.6 best solution, best possible 1.419952 (68.51 seconds)\n",
      "Cbc0010I After 12100 nodes, 3603 on tree, 1.6 best solution, best possible 1.419952 (69.34 seconds)\n",
      "Cbc0010I After 12200 nodes, 3660 on tree, 1.6 best solution, best possible 1.419952 (70.14 seconds)\n",
      "Cbc0010I After 12300 nodes, 3720 on tree, 1.6 best solution, best possible 1.419952 (71.04 seconds)\n",
      "Cbc0010I After 12400 nodes, 3779 on tree, 1.6 best solution, best possible 1.419952 (71.90 seconds)\n",
      "Cbc0010I After 12500 nodes, 3836 on tree, 1.6 best solution, best possible 1.419952 (72.69 seconds)\n",
      "Cbc0010I After 12600 nodes, 3894 on tree, 1.6 best solution, best possible 1.419952 (73.58 seconds)\n",
      "Cbc0010I After 12700 nodes, 3952 on tree, 1.6 best solution, best possible 1.419952 (74.45 seconds)\n",
      "Cbc0010I After 12800 nodes, 4012 on tree, 1.6 best solution, best possible 1.419952 (75.36 seconds)\n",
      "Cbc0010I After 12900 nodes, 4070 on tree, 1.6 best solution, best possible 1.419952 (76.30 seconds)\n",
      "Cbc0010I After 13000 nodes, 4128 on tree, 1.6 best solution, best possible 1.419952 (78.06 seconds)\n",
      "Cbc0010I After 13100 nodes, 4228 on tree, 1.6 best solution, best possible 1.419952 (79.37 seconds)\n",
      "Cbc0010I After 13200 nodes, 4328 on tree, 1.6 best solution, best possible 1.419952 (81.55 seconds)\n",
      "Cbc0010I After 13300 nodes, 4418 on tree, 1.6 best solution, best possible 1.419952 (82.40 seconds)\n",
      "Cbc0010I After 13400 nodes, 4491 on tree, 1.6 best solution, best possible 1.419952 (82.88 seconds)\n",
      "Cbc0010I After 13500 nodes, 4490 on tree, 1.6 best solution, best possible 1.419952 (83.62 seconds)\n",
      "Cbc0010I After 13600 nodes, 4488 on tree, 1.6 best solution, best possible 1.419952 (84.35 seconds)\n",
      "Cbc0010I After 13700 nodes, 4488 on tree, 1.6 best solution, best possible 1.419952 (85.45 seconds)\n",
      "Cbc0010I After 13800 nodes, 4487 on tree, 1.6 best solution, best possible 1.419952 (86.33 seconds)\n",
      "Cbc0010I After 13900 nodes, 4488 on tree, 1.6 best solution, best possible 1.419952 (87.44 seconds)\n",
      "Cbc0010I After 14000 nodes, 4487 on tree, 1.6 best solution, best possible 1.419952 (88.74 seconds)\n",
      "Cbc0010I After 14100 nodes, 4544 on tree, 1.6 best solution, best possible 1.419952 (90.91 seconds)\n",
      "Cbc0010I After 14200 nodes, 4604 on tree, 1.6 best solution, best possible 1.419952 (93.07 seconds)\n",
      "Cbc0010I After 14300 nodes, 4664 on tree, 1.6 best solution, best possible 1.419952 (94.19 seconds)\n",
      "Cbc0038I Full problem 992 rows 2751 columns, reduced to 19 rows 27 columns\n",
      "Cbc0010I After 14400 nodes, 4724 on tree, 1.6 best solution, best possible 1.419952 (95.16 seconds)\n",
      "Cbc0010I After 14500 nodes, 4782 on tree, 1.6 best solution, best possible 1.419952 (96.36 seconds)\n",
      "Cbc0010I After 14600 nodes, 4839 on tree, 1.6 best solution, best possible 1.419952 (98.01 seconds)\n",
      "Cbc0010I After 14700 nodes, 4892 on tree, 1.6 best solution, best possible 1.419952 (100.47 seconds)\n",
      "Cbc0010I After 14800 nodes, 4892 on tree, 1.6 best solution, best possible 1.419952 (101.79 seconds)\n",
      "Cbc0010I After 14900 nodes, 4935 on tree, 1.6 best solution, best possible 1.419952 (103.37 seconds)\n",
      "Cbc0010I After 15000 nodes, 4994 on tree, 1.6 best solution, best possible 1.419952 (104.74 seconds)\n",
      "Cbc0010I After 15100 nodes, 5053 on tree, 1.6 best solution, best possible 1.419952 (105.89 seconds)\n",
      "Cbc0010I After 15200 nodes, 5113 on tree, 1.6 best solution, best possible 1.419952 (107.86 seconds)\n",
      "Cbc0010I After 15300 nodes, 5172 on tree, 1.6 best solution, best possible 1.419952 (109.22 seconds)\n",
      "Cbc0010I After 15400 nodes, 5233 on tree, 1.6 best solution, best possible 1.419952 (110.36 seconds)\n",
      "Cbc0010I After 15500 nodes, 5289 on tree, 1.6 best solution, best possible 1.419952 (112.02 seconds)\n",
      "Cbc0010I After 15600 nodes, 5348 on tree, 1.6 best solution, best possible 1.419952 (113.18 seconds)\n",
      "Cbc0010I After 15700 nodes, 5407 on tree, 1.6 best solution, best possible 1.419952 (114.29 seconds)\n",
      "Cbc0010I After 15800 nodes, 5466 on tree, 1.6 best solution, best possible 1.419952 (116.12 seconds)\n",
      "Cbc0010I After 15900 nodes, 5561 on tree, 1.6 best solution, best possible 1.419952 (118.10 seconds)\n",
      "Cbc0010I After 16000 nodes, 5625 on tree, 1.6 best solution, best possible 1.419952 (119.28 seconds)\n",
      "Cbc0020I Exiting on maximum time\n",
      "Cbc0005I Partial search - best objective 1.6 (best possible 1.419952), took 524506 iterations and 16049 nodes (120.14 seconds)\n",
      "Cbc0032I Strong branching done 18608 times (93914 iterations), fathomed 1219 nodes and fixed 2654 variables\n",
      "Cbc0035I Maximum depth 1246, 14453 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 0 to 1.41995\n",
      "Probing was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.022 seconds)\n",
      "Gomory was tried 12 times and created 50 cuts of which 0 were active after adding rounds of cuts (0.026 seconds)\n",
      "Knapsack was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.011 seconds)\n",
      "Clique was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.001 seconds)\n",
      "MixedIntegerRounding2 was tried 13703 times and created 35735 cuts of which 0 were active after adding rounds of cuts (27.283 seconds)\n",
      "FlowCover was tried 12 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.027 seconds)\n",
      "TwoMirCuts was tried 12 times and created 2 cuts of which 0 were active after adding rounds of cuts (0.014 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.001 seconds)\n",
      "\n",
      "Result - Stopped on time limit\n",
      "\n",
      "Objective value:                1.60000000\n",
      "Lower bound:                    1.420\n",
      "Gap:                            0.13\n",
      "Enumerated nodes:               16049\n",
      "Total iterations:               524506\n",
      "Time (CPU seconds):             118.83\n",
      "Time (Wallclock seconds):       120.16\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       118.84   (Wallclock seconds):       120.17\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sanity check\n",
    "\n",
    "- All pianists should have 1 track in every split (train/val/test)\n",
    "- Splits should be roughly 8/1/1\n",
    "- Splits should be roughly proportional between trio/solo\n",
    "- Composition split:\n",
    "    - No leaks of composition between splits\n",
    "- Album split:\n",
    "    - No leaks of album between splits"
   ],
   "id": "2ce77520238a1e16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:36:56.564557Z",
     "start_time": "2026-02-06T13:36:56.485609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Each pianist should have one recording in every split\n",
    "for pianist in DESIRED_PIANISTS:\n",
    "    for (df_name, df_) in zip([\"album\", \"comp\"], [album_df, comp_df]):\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            got = df_[(df_[\"pianist\"] == pianist) & (df_[\"split\"] == split)]\n",
    "            assert len(got) >= 1, f\"Pianist {pianist} does not appear in split {split} for df {df_name}\""
   ],
   "id": "4c6b32ac29d5c0a9",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:39:39.410248Z",
     "start_time": "2026-02-06T13:39:39.399611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splits should be approximately 8/1/1\n",
    "for (df_name, df_) in zip([\"album\", \"comp\"], [album_df, comp_df]):\n",
    "    total_tracks = len(df_)\n",
    "    for split, desired_proportion in zip([\"train\", \"val\", \"test\"], [0.8, 0.1, 0.1]):\n",
    "        actual_proportion = len(df_[df_[\"split\"] == split]) / total_tracks\n",
    "        assert math.isclose(actual_proportion, desired_proportion, abs_tol=0.01)\n"
   ],
   "id": "a374cf4d8b8d17c7",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T13:43:25.975286Z",
     "start_time": "2026-02-06T13:43:25.960688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# No leaks of compositions/albums between splits\n",
    "for column_name, df_ in zip([\"album_name\", \"composition_canonic\"], [album_df, comp_df]):\n",
    "    for split_a in [\"train\", \"val\", \"test\"]:\n",
    "        split_a_df = df_[df_[\"split\"] == split_a]\n",
    "        split_a_comps = set(split_a_df[column_name].unique().tolist())\n",
    "        other_splits = [i for i in [\"train\", \"val\", \"test\"] if i != split_a]\n",
    "        for split_b in other_splits:\n",
    "            split_b_df = df_[df_[\"split\"] == split_b]\n",
    "            split_b_comps = set(split_b_df[column_name].unique().tolist())\n",
    "            shared = set.intersection(split_a_comps, split_b_comps)\n",
    "            assert len(shared) == 0"
   ],
   "id": "74de807c848731c4",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T16:21:31.047952Z",
     "start_time": "2026-02-06T16:21:31.021638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for (df_name, df_) in zip([\"album\", \"comp\"], [album_df, comp_df]):\n",
    "    total_tracks = len(df_)\n",
    "    print(total_tracks)"
   ],
   "id": "cdbeeabb1ac33e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1629\n",
      "1629\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d3736529bba43ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
